Not using distributed mode
Namespace(data_path='~/Kunal/edgeai-modelopt_demo/imagenette', dataset='folder', annotation_prefix='instances', model='mobilenet_v2', device='cuda', gpus=4, batch_size=128, epochs=10, workers=16, opt='sgd', lr=0.1, momentum=0.9, weight_decay=4e-05, norm_weight_decay=None, bias_weight_decay=None, transformer_embedding_decay=None, label_smoothing=0.0, mixup_alpha=0.0, cutmix_alpha=0.0, lr_scheduler='cosineannealinglr', lr_warmup_epochs=1, lr_warmup_method='constant', lr_warmup_decay=0.01, lr_step_size=30, lr_gamma=0.1, lr_min=0.0, print_freq=100, output_dir='./output/mobilenet_v2/2024_01_31_22_38_18', resume='', start_epoch=0, cache_dataset=False, sync_bn=False, test_only=False, auto_augment=None, ra_magnitude=9, augmix_severity=3, random_erase=0.0, amp=False, world_size=1, dist_url='env://', distributed=False, parallel=0, model_ema=False, model_ema_steps=32, model_ema_decay=0.99998, use_deterministic_algorithms=False, interpolation='bilinear', val_resize_size=232, val_crop_size=224, train_crop_size=224, clip_grad_norm=None, ra_sampler=False, ra_reps=3, weights='/home/a0507161/Kunal/edgeai-modelopt_demo/output/mobilenet_v2/checkpoint.pth', weights_state_dict_name='model', model_surgery=0, surgery_json='', quantization=0, quantization_type=None, pruning=0, pruning_ratio=0.640625, pruning_type='channel', pruning_class='blend', pruning_global=0, pruning_init_train_ep=5, pruning_m=None, compile_model=0, opset_version=18, train_epoch_size_factor=0.0, val_epoch_size_factor=0.0, weights_url='/home/a0507161/Kunal/edgeai-modelopt_demo/output/mobilenet_v2/checkpoint.pth', weights_enum=None)
Loading data
Loading training data
Took 0.039446353912353516
Loading validation data
Creating data loaders
Creating model
loading pretrained checkpoint for training: /home/a0507161/Kunal/edgeai-modelopt_demo/output/mobilenet_v2/checkpoint.pth
Start training
Epoch: [0]  [ 0/74]  eta: 0:01:24  lr: 0.001  img/s: 867.747293900872  loss: 0.2511 (0.2511)  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 1.1473  data: 0.9998  max mem: 9902
Epoch: [0] Total time: 0:00:11
/home/a0507161/.pyenv/versions/3.10.13/envs/py310/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning:

The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.

Test:   [ 0/31]  eta: 0:00:23  loss: 0.2041 (0.2041)  acc1: 95.3125 (95.3125)  acc5: 98.4375 (98.4375)  time: 0.7681  data: 0.7149  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 87.873 Acc@5 98.955
============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

Epoch: [1]  [ 0/74]  eta: 0:01:00  lr: 0.1  img/s: 878.9260967935222  loss: 0.2685 (0.2685)  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.8166  data: 0.6709  max mem: 9902
Epoch: [1] Total time: 0:00:11
Test:   [ 0/31]  eta: 0:00:21  loss: 0.2869 (0.2869)  acc1: 92.1875 (92.1875)  acc5: 98.4375 (98.4375)  time: 0.7079  data: 0.6657  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 81.911 Acc@5 97.987
Epoch: [2]  [ 0/74]  eta: 0:01:01  lr: 0.09698463103929543  img/s: 878.2776253646056  loss: 0.5774 (0.5774)  acc1: 85.9375 (85.9375)  acc5: 96.0938 (96.0938)  time: 0.8296  data: 0.6839  max mem: 9902
Epoch: [2] Total time: 0:00:11
Test:   [ 0/31]  eta: 0:00:22  loss: 0.5516 (0.5516)  acc1: 85.9375 (85.9375)  acc5: 96.0938 (96.0938)  time: 0.7397  data: 0.6941  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 81.834 Acc@5 98.344
Epoch: [3]  [ 0/74]  eta: 0:01:04  lr: 0.08830222215594889  img/s: 727.003378602545  loss: 0.4583 (0.4583)  acc1: 83.5938 (83.5938)  acc5: 98.4375 (98.4375)  time: 0.8685  data: 0.6924  max mem: 9902
Epoch: [3] Total time: 0:00:11
Test:   [ 0/31]  eta: 0:00:27  loss: 0.3452 (0.3452)  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.8726  data: 0.7974  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 83.694 Acc@5 98.268
Epoch: [4]  [ 0/74]  eta: 0:01:05  lr: 0.075  img/s: 869.9971835778932  loss: 0.4795 (0.4795)  acc1: 85.1562 (85.1562)  acc5: 99.2188 (99.2188)  time: 0.8850  data: 0.7379  max mem: 9902
Epoch: [4] Total time: 0:00:11
Test:   [ 0/31]  eta: 0:00:31  loss: 0.3151 (0.3151)  acc1: 92.1875 (92.1875)  acc5: 96.8750 (96.8750)  time: 1.0299  data: 0.9874  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 83.261 Acc@5 98.242
Epoch: [5]  [ 0/74]  eta: 0:01:32  lr: 0.058682408883346526  img/s: 869.8407209262385  loss: 0.3466 (0.3466)  acc1: 89.0625 (89.0625)  acc5: 98.4375 (98.4375)  time: 1.2463  data: 1.0991  max mem: 9902
Epoch: [5] Total time: 0:00:12
Test:   [ 0/31]  eta: 0:00:23  loss: 0.2902 (0.2902)  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.7727  data: 0.7271  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 84.433 Acc@5 98.497
Epoch: [6]  [ 0/74]  eta: 0:01:05  lr: 0.041317591116653486  img/s: 796.8529534433958  loss: 0.3001 (0.3001)  acc1: 91.4062 (91.4062)  acc5: 97.6562 (97.6562)  time: 0.8853  data: 0.7247  max mem: 9902
Epoch: [6] Total time: 0:00:11
Test:   [ 0/31]  eta: 0:00:22  loss: 0.2153 (0.2153)  acc1: 92.9688 (92.9688)  acc5: 98.4375 (98.4375)  time: 0.7377  data: 0.6956  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 86.726 Acc@5 98.854
Epoch: [7]  [ 0/74]  eta: 0:01:03  lr: 0.025000000000000012  img/s: 858.7873502359433  loss: 0.3825 (0.3825)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.8564  data: 0.7073  max mem: 9902
Epoch: [7] Total time: 0:00:12
Test:   [ 0/31]  eta: 0:00:22  loss: 0.1982 (0.1982)  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.7134  data: 0.6687  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 87.159 Acc@5 99.006
Epoch: [8]  [ 0/74]  eta: 0:01:04  lr: 0.011697777844051105  img/s: 772.8219562998694  loss: 0.3616 (0.3616)  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.8710  data: 0.7053  max mem: 9902
Epoch: [8] Total time: 0:00:12
Test:   [ 0/31]  eta: 0:00:26  loss: 0.1524 (0.1524)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 0.8531  data: 0.8011  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 88.280 Acc@5 99.108
============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============
verbose: False, log level: Level.ERROR
======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================

Epoch: [9]  [ 0/74]  eta: 0:01:09  lr: 0.0030153689607045845  img/s: 854.4124414539008  loss: 0.3606 (0.3606)  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.9329  data: 0.7831  max mem: 9902
Epoch: [9] Total time: 0:00:12
Test:   [ 0/31]  eta: 0:00:33  loss: 0.1666 (0.1666)  acc1: 94.5312 (94.5312)  acc5: 98.4375 (98.4375)  time: 1.0833  data: 1.0410  max mem: 9902
Test:  Total time: 0:00:02
Test:  Acc@1 88.127 Acc@5 99.134
