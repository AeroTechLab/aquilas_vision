help_descriptions:
  common: {}
  compilation:
    calibration_frames:
      description: Calibration is a process of improving the accuracy during fixed
        point quantization. Typically, higher number of Calibration Frames give higher
        accuracy, but it can also be time consuming.
      name: Calibration Frames
    calibration_iterations:
      description: Calibration is a process of improving the accuracy during fixed
        point quantization. Calibration happens in iterations. Typically, higher number
        of Calibration Iterations give higher accuracy, but it can also be time consuming.
      name: Calibration Iterations
    detection_threshold:
      description: 'Also called Confidence Threshold. A threshold used to select good
        detection boxes. This is typically applied before a before the Non Max Suppression.
        Higher Detection Threshold means less false detections (False Positives),
        but may also result in misses (False Negatives). '
      name: Detection Threshold
    detection_top_k:
      description: 'Number of detection boxes to be selected during the initial shortlisting
        before the Non Max Suppression.A higher number is typically used while measuring
        accuracy, but may impact the performance. '
      name: Detection TopK
    tensor_bits:
      description: 'Bitdepth used to quantize the weights and activations in the neural
        network. The neural network inference happens at this bit precision. '
      name: Tensor Bits
  dataset: {}
  training:
    batch_size:
      description: Batch size specifies the number of inputs that are propagated through
        the neural network in one iteration. Several such iterations make up one Epoch.Higher
        batch size require higher memory and too low batch size can typically impact
        the accuracy.
      name: Batch Size
    learning_rate:
      description: Learning Rate determines the step size used by the optimization
        algorithm at each iteration while moving towards the optimal solution. It
        is a hyper parameter that can be tuned to get best accuracy. Eg. A small Learning
        Rate typically gives good accuracy while fine tuning a model for a different
        task.
      name: Learning Rate
    training_epochs:
      description: Epoch is a term that is used to indicate a pass over the entire
        training dataset. It is a hyper parameter that can be tuned to get best accuracy.
        Eg. A model trained for 30 Epochs may give better accuracy than a model trained
        for 15 Epochs.
      name: Epochs
    weight_decay:
      description: Weight decay is a regularization technique that can improve stability
        and generalization of a machine learning algorithm. It is typically done using
        L2 regularization that penalizes parameters (weights, biases) according to
        their L2 norm.
      name: Weight Decay
model_descriptions:
  mobilenet_v2_lite_tv:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: classification
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 1
      model_compilation_id: cl-6070
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
      download_path: '{download_path}/pretrained/mobilenet_v2_lite_tv'
      download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/classification/imagenet1k/edgeai-tv/mobilenet_v2_20191224_checkpoint.pth
    training:
      batch_size: 64
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 224
      input_resize: 256
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: backbone
      model_checkpoint_path: null
      model_export_path: null
      model_name: mobilenet_v2_lite_tv
      model_packaged_path: null
      model_proto_path: null
      model_training_id: mobilenet_v2_lite
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/mobilenet_v2_lite_tv'
        download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/classification/imagenet1k/edgeai-tv/mobilenet_v2_20191224_checkpoint.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 72.13
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 2
          performance_fps: 477
          performance_infer_time_ms: 2.0964360587002098
        AM68A:
          accuracy_factor: 72.13
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 2
          performance_fps: 477
          performance_infer_time_ms: 2.0964360587002098
        TDA4VM:
          accuracy_factor: 72.13
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 2
          performance_fps: 477
          performance_infer_time_ms: 2.0964360587002098
      training_backend: edgeai_torchvision
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
  regnet_x_400mf_tv:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: classification
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 1
      model_compilation_id: cl-6160
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
      download_path: '{download_path}/pretrained/torch/hub/checkpoints'
      download_url: https://download.pytorch.org/models/regnet_x_400mf-62229a5f.pth
    training:
      batch_size: 64
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 224
      input_resize: 256
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: backbone
      model_checkpoint_path: null
      model_export_path: null
      model_name: regnet_x_400mf_tv
      model_packaged_path: null
      model_proto_path: null
      model_training_id: regnet_x_400mf
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/torch/hub/checkpoints'
        download_url: https://download.pytorch.org/models/regnet_x_400mf-62229a5f.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 72.834
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 1
          performance_fps: 288
          performance_infer_time_ms: 3.4722222222222223
        AM68A:
          accuracy_factor: 72.834
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 1
          performance_fps: 288
          performance_infer_time_ms: 3.4722222222222223
        TDA4VM:
          accuracy_factor: 72.834
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 1
          performance_fps: 288
          performance_infer_time_ms: 3.4722222222222223
      training_backend: edgeai_torchvision
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
  regnet_x_800mf_tv:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: classification
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 1
      model_compilation_id: cl-6170
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
      download_path: '{download_path}/pretrained/torch/hub/checkpoints'
      download_url: https://download.pytorch.org/models/regnet_x_800mf-ad17e45c.pth
    training:
      batch_size: 64
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 224
      input_resize: 256
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: backbone
      model_checkpoint_path: null
      model_export_path: null
      model_name: regnet_x_800mf_tv
      model_packaged_path: null
      model_proto_path: null
      model_training_id: regnet_x_800mf
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/torch/hub/checkpoints'
        download_url: https://download.pytorch.org/models/regnet_x_800mf-ad17e45c.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 75.212
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 0
          performance_fps: 272
          performance_infer_time_ms: 3.676470588235294
        AM68A:
          accuracy_factor: 75.212
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 0
          performance_fps: 272
          performance_infer_time_ms: 3.676470588235294
        TDA4VM:
          accuracy_factor: 75.212
          accuracy_unit: Accuracy Top-1%
          model_selection_factor: 0
          performance_fps: 272
          performance_infer_time_ms: 3.676470588235294
      training_backend: edgeai_torchvision
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
  yolox_nano_lite_mmdet:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: detection
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 0
      model_compilation_id: od-8200
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      runtime_options:
        advanced_options:output_feature_16bit_names_list: 1213, 1212, 1211, 1197,
          1196, 1195, 1181, 1180, 1179
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
    - download_path: '{download_path}/pretrained/yolox_nano_lite_mmdet'
      download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_nano_lite_416x416_20220214_checkpoint.pth
    training:
      batch_size: 8
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 416
      input_resize: 416
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: yolox
      model_checkpoint_path: null
      model_export_path: null
      model_name: yolox_nano_lite_416x416_mmdet
      model_packaged_path: null
      model_proto_path: null
      model_training_id: yolox_nano_lite
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/yolox_nano_lite_mmdet'
        download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_nano_lite_416x416_20220214_checkpoint.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 40.1
          accuracy_factor2: 24.8
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 2
          performance_fps: 287
          performance_infer_time_ms: 3.484320557491289
        AM68A:
          accuracy_factor: 40.1
          accuracy_factor2: 24.8
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 2
          performance_fps: 287
          performance_infer_time_ms: 3.484320557491289
        TDA4VM:
          accuracy_factor: 40.1
          accuracy_factor2: 24.8
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 2
          performance_fps: 287
          performance_infer_time_ms: 3.484320557491289
      training_backend: edgeai_mmdetection
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
  yolox_s_lite_mmdet:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: detection
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 0
      model_compilation_id: od-8220
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      runtime_options:
        advanced_options:output_feature_16bit_names_list: 1213, 1212, 1211, 1197,
          1196, 1195, 1181, 1180, 1179
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
    - download_path: '{download_path}/pretrained/yolox_s_lite_mmdet'
      download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_s_lite_640x640_20220221_checkpoint.pth
    training:
      batch_size: 8
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 640
      input_resize: 640
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: yolox
      model_checkpoint_path: null
      model_export_path: null
      model_name: yolox_s_lite_640x640_mmdet
      model_packaged_path: null
      model_proto_path: null
      model_training_id: yolox_s_lite
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/yolox_s_lite_mmdet'
        download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_s_lite_640x640_20220221_checkpoint.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 56.9
          accuracy_factor2: 38.3
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 0
          performance_fps: 102
          performance_infer_time_ms: 9.803921568627452
        AM68A:
          accuracy_factor: 56.9
          accuracy_factor2: 38.3
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 0
          performance_fps: 102
          performance_infer_time_ms: 9.803921568627452
        TDA4VM:
          accuracy_factor: 56.9
          accuracy_factor2: 38.3
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 0
          performance_fps: 102
          performance_infer_time_ms: 9.803921568627452
      training_backend: edgeai_mmdetection
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
  yolox_tiny_lite_mmdet:
    common:
      download_path: ./data/downloads
      project_path: null
      project_run_path: null
      projects_path: ./data/projects
      run_name: '{date-time}/{model_name}'
      target_device: null
      target_machine: evm
      target_module: vision
      task_type: detection
      verbose_mode: true
    compilation:
      calibration_frames: 10
      calibration_iterations: 10
      capture_log: true
      compilation_path: null
      detection_threshold: 0.6
      detection_top_k: 200
      enable: true
      input_optimization: true
      log_file_path: null
      log_summary_regex: null
      metric:
        label_offset_pred: 0
      model_compilation_id: od-8210
      model_compiled_path: null
      model_packaged_path: null
      model_visualization_path: null
      num_frames: null
      num_output_frames: 50
      output_tensors_path: null
      runtime_options:
        advanced_options:output_feature_16bit_names_list: 1213, 1212, 1211, 1197,
          1196, 1195, 1181, 1180, 1179
      save_output: true
      summary_file_path: null
      tensor_bits: 8
      tidl_offload: true
    dataset:
      annotation_dir: annotations
      annotation_format: coco_json
      annotation_path_splits: null
      annotation_prefix: instances
      data_dir: images
      data_path_splits: null
      dataset_download: true
      dataset_name: null
      dataset_path: null
      dataset_reload: false
      enable: true
      extract_path: null
      input_annotation_path: null
      input_data_path: null
      max_num_files: null
      split_factor: 0.75
      split_names:
      - train
      - val
    download:
    - download_path: '{download_path}/pretrained/yolox_tiny_lite_mmdet'
      download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_tiny_lite_416x416_20220217_checkpoint.pth
    training:
      batch_size: 8
      dataset_path: null
      distributed: true
      enable: true
      input_cropsize: 416
      input_resize: 416
      learning_rate: 0.002
      log_file_path: null
      log_summary_regex: null
      model_architecture: yolox
      model_checkpoint_path: null
      model_export_path: null
      model_name: yolox_tiny_lite_416x416_mmdet
      model_packaged_path: null
      model_proto_path: null
      model_training_id: yolox_tiny_lite
      num_classes: null
      num_gpus: 0
      num_last_epochs: 5
      pretrained_checkpoint_path:
        download_path: '{download_path}/pretrained/yolox_tiny_lite_mmdet'
        download_url: https://software-dl.ti.com/jacinto7/esd/modelzoo/latest/models/vision/detection/coco/edgeai-mmdet/yolox_tiny_lite_416x416_20220217_checkpoint.pth
      project_path: null
      summary_file_path: null
      target_devices:
        AM62A:
          accuracy_factor: 47.4
          accuracy_factor2: 30.5
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 1
          performance_fps: 220
          performance_infer_time_ms: 4.545454545454546
        AM68A:
          accuracy_factor: 47.4
          accuracy_factor2: 30.5
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 1
          performance_fps: 220
          performance_infer_time_ms: 4.545454545454546
        TDA4VM:
          accuracy_factor: 47.4
          accuracy_factor2: 30.5
          accuracy_unit: AP50%
          accuracy_unit2: AP[.5:.95]%
          model_selection_factor: 1
          performance_fps: 220
          performance_infer_time_ms: 4.545454545454546
      training_backend: edgeai_mmdetection
      training_device: null
      training_devices:
        cpu: true
        cuda: true
      training_epochs: 15
      training_master_port: 29500
      training_path: null
      warmup_epochs: 1
      weight_decay: 0.0001
preset_descriptions:
  AM62A:
    classification:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
    detection:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.05
          detection_top_k: 500
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
  AM68A:
    classification:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
    detection:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.05
          detection_top_k: 500
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
  TDA4VM:
    classification:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: null
          detection_top_k: null
          tensor_bits: 8
    detection:
      best_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.05
          detection_top_k: 500
          tensor_bits: 16
      best_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 1
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      default_preset:
        compilation:
          calibration_frames: 10
          calibration_iterations: 10
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_accuracy_preset:
        compilation:
          calibration_frames: 25
          calibration_iterations: 25
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
      high_speed_preset:
        compilation:
          calibration_frames: 5
          calibration_iterations: 5
          detection_threshold: 0.6
          detection_top_k: 200
          tensor_bits: 8
sample_dataset_descriptions:
  animal_classification:
    common:
      task_type: classification
    dataset:
      dataset_name: animal_classification
      input_data_path: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/animal_classification.zip
    info:
      dataset_description: Example cat-dog image classification dataset with 2 categories
        and 118 images
      dataset_detailed_name: Animal classification
      dataset_frames: 118
      dataset_license: CC0 1.0 Universal Public Domain Dedication
      dataset_size: 16137224
      dataset_source: CC0 Public Domain Images from creativecommons.org, annotations
        by TI
      dataset_url: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/animal_classification.zip
  animal_detection:
    common:
      task_type: detection
    dataset:
      dataset_name: animal_detection
      input_data_path: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/animal_detection.zip
    info:
      dataset_description: Example cat-dog object detection dataset with 2 categories
        and 99 images
      dataset_detailed_name: Animal detection
      dataset_frames: 99
      dataset_license: CC0 1.0 Universal Public Domain Dedication
      dataset_size: 15290214
      dataset_source: CC0 Public Domain Images from creativecommons.org, annotations
        by TI
      dataset_url: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/animal_detection.zip
  tiscapes2017_driving:
    common:
      task_type: detection
    dataset:
      dataset_name: tiscapes2017_driving
      input_data_path: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/tiscapes2017_driving.zip
    info:
      dataset_description: Example driving scenario object detection dataset with
        4 categories and 2116 images
      dataset_detailed_name: TIScapes driving detection
      dataset_frames: 2116
      dataset_license: BSD 3-Clause
      dataset_size: 461038628
      dataset_source: Images & annotations from TI
      dataset_url: http://software-dl.ti.com/jacinto7/esd/modelzoo/latest/datasets/tiscapes2017_driving.zip
target_device_descriptions:
  AM62A:
    device_details: "\nEfficient 2 TOPs AI capabilities at edge\nSpecification:\n\
      * 2 TOPS Deep Learning accelerator\n* Quad Arm\xAE Cortex\xAE-A53\n* Integrated\
      \ ISP\n* More details : https://www.ti.com/product/AM62A\n\nImportant Links:\n\
      * Development board: https://www.ti.com/tool/SK-AM62A\n* Software Development\
      \ Kit (SDK): https://www.ti.com/tool/download/PROCESSOR-SDK-LINUX-AM62A/\n*\
      \ Edge AI summary: https://ti.com/edgeai\n* Edge AI tools introduction: https://dev.ti.com/edgeai/\n\
      * Edge AI model development information: https://github.com/TexasInstruments/edgeai\n"
    device_name: AM62A
    device_selection_factor: 0
    device_type: MPU
  AM68A:
    device_details: "\nEfficient 8 TOPs AI capabilities at edge\nSpecification:\n\
      * 8 TOPS Deep Learning accelerator\n* Dual Arm\xAE Cortex\xAE-A72\n* Integrated\
      \ ISP\n* More details : https://www.ti.com/product/AM68A\n\nImportant Links:\n\
      * Development board: https://www.ti.com/tool/SK-AM68A\n* Software Development\
      \ Kit (SDK): https://www.ti.com/tool/download/PROCESSOR-SDK-LINUX-AM68A/\n*\
      \ Edge AI summary: https://ti.com/edgeai\n* Edge AI tools introduction: https://dev.ti.com/edgeai/\n\
      * Edge AI model development information: https://github.com/TexasInstruments/edgeai\n"
    device_name: AM68A
    device_selection_factor: 1
    device_type: MPU
  TDA4VM:
    device_details: "\nEfficient 8 TOPs AI capabilities at edge\nSpecification:\n\
      * 8 TOPS Deep Learning accelerator\n* Dual Arm\xAE Cortex\xAE-A72\n* Integrated\
      \ ISP\n* More details : https://www.ti.com/product/TDA4VM\n\nImportant Links:\n\
      * Development board: https://www.ti.com/tool/SK-TDA4VM\n* Software Development\
      \ Kit (SDK): https://www.ti.com/tool/download/PROCESSOR-SDK-LINUX-SK-TDA4VM/\n\
      * Edge AI summary: https://ti.com/edgeai\n* Edge AI tools introduction: https://dev.ti.com/edgeai/\n\
      * Edge AI model development information: https://github.com/TexasInstruments/edgeai\n"
    device_name: TDA4VM
    device_selection_factor: 2
    device_type: MPU
task_descriptions:
  classification:
    stages:
    - dataset
    - training
    - compilation
    target_devices: &id001
    - TDA4VM
    - AM62A
    - AM68A
    target_module: vision
    task_name: Image Classification
  detection:
    stages:
    - dataset
    - training
    - compilation
    target_devices: *id001
    target_module: vision
    task_name: Object Detection
training_module_descriptions:
  edgeai_mmdetection:
  - detection
  edgeai_torchvision:
  - classification
version_descriptions:
  sdk_release: 08_06
  sdk_version: '8.6'
  version: '8.6'
